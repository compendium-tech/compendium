// Code generated by mockery; DO NOT EDIT.
// github.com/vektra/mockery
// template: testify

package interop

import (
	"context"

	"github.com/compendium-tech/compendium/application-service/internal/domain"
	mock "github.com/stretchr/testify/mock"
)

// NewMockLLMService creates a new instance of MockLLMService. It also registers a testing interface on the mock and a cleanup function to assert the mocks expectations.
// The first argument is typically a *testing.T value.
func NewMockLLMService(t interface {
	mock.TestingT
	Cleanup(func())
}) *MockLLMService {
	mock := &MockLLMService{}
	mock.Mock.Test(t)

	t.Cleanup(func() { mock.AssertExpectations(t) })

	return mock
}

// MockLLMService is an autogenerated mock type for the LLMService type
type MockLLMService struct {
	mock.Mock
}

type MockLLMService_Expecter struct {
	mock *mock.Mock
}

func (_m *MockLLMService) EXPECT() *MockLLMService_Expecter {
	return &MockLLMService_Expecter{mock: &_m.Mock}
}

// GenerateResponse provides a mock function for the type MockLLMService
func (_mock *MockLLMService) GenerateResponse(ctx context.Context, chatHistory []domain.LLMMessage, tools []domain.LLMToolDefinition, structuredOutputSchema *domain.LLMSchema) domain.LLMMessage {
	ret := _mock.Called(ctx, chatHistory, tools, structuredOutputSchema)

	if len(ret) == 0 {
		panic("no return value specified for GenerateResponse")
	}

	var r0 domain.LLMMessage
	if returnFunc, ok := ret.Get(0).(func(context.Context, []domain.LLMMessage, []domain.LLMToolDefinition, *domain.LLMSchema) domain.LLMMessage); ok {
		r0 = returnFunc(ctx, chatHistory, tools, structuredOutputSchema)
	} else {
		r0 = ret.Get(0).(domain.LLMMessage)
	}
	return r0
}

// MockLLMService_GenerateResponse_Call is a *mock.Call that shadows Run/Return methods with type explicit version for method 'GenerateResponse'
type MockLLMService_GenerateResponse_Call struct {
	*mock.Call
}

// GenerateResponse is a helper method to define mock.On call
//   - ctx context.Context
//   - chatHistory []domain.LLMMessage
//   - tools []domain.LLMToolDefinition
//   - structuredOutputSchema *domain.LLMSchema
func (_e *MockLLMService_Expecter) GenerateResponse(ctx interface{}, chatHistory interface{}, tools interface{}, structuredOutputSchema interface{}) *MockLLMService_GenerateResponse_Call {
	return &MockLLMService_GenerateResponse_Call{Call: _e.mock.On("GenerateResponse", ctx, chatHistory, tools, structuredOutputSchema)}
}

func (_c *MockLLMService_GenerateResponse_Call) Run(run func(ctx context.Context, chatHistory []domain.LLMMessage, tools []domain.LLMToolDefinition, structuredOutputSchema *domain.LLMSchema)) *MockLLMService_GenerateResponse_Call {
	_c.Call.Run(func(args mock.Arguments) {
		var arg0 context.Context
		if args[0] != nil {
			arg0 = args[0].(context.Context)
		}
		var arg1 []domain.LLMMessage
		if args[1] != nil {
			arg1 = args[1].([]domain.LLMMessage)
		}
		var arg2 []domain.LLMToolDefinition
		if args[2] != nil {
			arg2 = args[2].([]domain.LLMToolDefinition)
		}
		var arg3 *domain.LLMSchema
		if args[3] != nil {
			arg3 = args[3].(*domain.LLMSchema)
		}
		run(
			arg0,
			arg1,
			arg2,
			arg3,
		)
	})
	return _c
}

func (_c *MockLLMService_GenerateResponse_Call) Return(lLMMessage domain.LLMMessage) *MockLLMService_GenerateResponse_Call {
	_c.Call.Return(lLMMessage)
	return _c
}

func (_c *MockLLMService_GenerateResponse_Call) RunAndReturn(run func(ctx context.Context, chatHistory []domain.LLMMessage, tools []domain.LLMToolDefinition, structuredOutputSchema *domain.LLMSchema) domain.LLMMessage) *MockLLMService_GenerateResponse_Call {
	_c.Call.Return(run)
	return _c
}
